{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T03:57:03.299844Z",
     "start_time": "2019-04-13T03:57:03.266445Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "del sys\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import database_creation.modeling_task as modeling_task\n",
    "from toolbox.utils import to_class_name\n",
    "from toolbox.parameters import MIN_ASSIGNMENTS, MIN_ANSWERS, EXCLUDE_PILOT, DROP_LAST, K_CROSS_VALIDATION, \\\n",
    "    MODELING_TASK_SHORT_SIZE, MODELING_TASK_SEED, BASELINES_SPLIT_VALID_PROPORTION, \\\n",
    "    BASELINES_SPLIT_TEST_PROPORTION, MODELS_SPLIT_VALID_PROPORTION, MODELS_SPLIT_TEST_PROPORTION\n",
    "from toolbox.paths import ANNOTATION_TASK_RESULTS_PATH, MODELING_TASK_FOR_BASELINES_PATH, \\\n",
    "    MODELING_TASK_FOR_MODELS_PATH\n",
    "\n",
    "root = \"../\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"task\": \"context_free\",\n",
    "    \"batch_size\": 64,\n",
    "    \"short\": True,\n",
    "    \"cross_validation\": False,\n",
    "    \"no_save\": True,\n",
    "    \"silent\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = to_class_name(args['task'])\n",
    "batch_size = args['batch_size']\n",
    "short = args['short']\n",
    "k_cross_validation = int(args['cross_validation']) * K_CROSS_VALIDATION\n",
    "save = not args['no_save']\n",
    "silent = args['silent']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create modeling task\n",
    "### Baselines split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = getattr(modeling_task, task_name)(min_assignments=MIN_ASSIGNMENTS,\n",
    "                                         min_answers=MIN_ANSWERS,\n",
    "                                         exclude_pilot=EXCLUDE_PILOT,\n",
    "                                         annotation_results_path=root + ANNOTATION_TASK_RESULTS_PATH,\n",
    "                                         batch_size=batch_size,\n",
    "                                         drop_last=DROP_LAST,\n",
    "                                         k_cross_validation=None,\n",
    "                                         valid_proportion=BASELINES_SPLIT_VALID_PROPORTION,\n",
    "                                         test_proportion=BASELINES_SPLIT_TEST_PROPORTION,\n",
    "                                         random_seed=MODELING_TASK_SEED,\n",
    "                                         save=save,\n",
    "                                         silent=silent,\n",
    "                                         results_path=root + MODELING_TASK_FOR_BASELINES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the modeling task...\n",
      "Computing the annotated queries...\n",
      "Initial length of queries: 0.\n",
      "Object loaded from ../results/annotation_task/annotations/v1_0_pilot/task/queries_short.pkl.\n",
      "Object loaded from ../results/annotation_task/annotations/v1_1_pilot/task/queries_short.pkl.\n",
      "Object loaded from ../results/annotation_task/annotations/v2_0/task/queries_short.pkl.\n",
      "Object loaded from ../results/annotation_task/annotations/v2_1/task/queries.pkl.\n",
      "Object loaded from ../results/annotation_task/annotations/v2_2/task/queries.pkl.\n",
      "Final length of queries: 63141.\n",
      "Done. Elapsed time: 1s.\n",
      "\n",
      "Computing the annotations...\n",
      "Initial length of annotations: 0.\n",
      "pilot_00a.csv loaded from annotations/v1_0_pilot/results/pilot_00a.csv\n",
      "Discarding \"The priest and the student\"\n",
      "pilot_00b.csv loaded from annotations/v1_0_pilot/results/pilot_00b.csv\n",
      "pilot_01a.csv loaded from annotations/v1_1_pilot/results/pilot_01a.csv\n",
      "pilot_01b.csv loaded from annotations/v1_1_pilot/results/pilot_01b.csv\n",
      "Discarding \"France and its former colonies\"\n",
      "Discarding \"The country and its former colonies\"\n",
      "batch_00 loaded from annotations/v2_0/results/batch_00_complete.csv\n",
      "Correcting \"n this article, Nevada and Ohio are discussed. The two American states...\" to \" The two American states...\"\n",
      "Correcting \"In this article, California and Oregon are discussed. The two neighboring states...\" to \" The two neighboring states...\"\n",
      "Correcting \"In this article, California and Oregon are discussed. The two West Coast states...\" to \" The two West Coast states...\"\n",
      "batch_01 loaded from annotations/v2_0/results/batch_01_complete.csv\n",
      "Discarding \"The\"\n",
      "Discarding \"The four people involved in the Rafferty and Parker murder case\"\n",
      "Discarding \"The two people involved in the accusations against Mr. Brookins and Mr. Hernandez\"\n",
      "Discarding \"The Canadian and American politicians\"\n",
      "Correcting \"THE CHESS CHAMPIONS\" to \"The chess champions\"\n",
      "Correcting \"THE WHITE AND BLACK\" to \"The white and black\"\n",
      "Discarding \"The white and black\"\n",
      "Discarding \"The North and South America countries\"\n",
      "Discarding \"Both are politlca entities\"\n",
      "batch_02 loaded from annotations/v2_1/results/batch_02_complete.csv\n",
      "Discarding \"Both groups have a military wing\"\n",
      "Discarding \"The financial/media concern\"\n",
      "Discarding \"Both countries are in Western Asia\"\n",
      "Correcting \"FOOTBALL TEAM\" to \"Football team\"\n",
      "batch_03 loaded from annotations/v2_1/results/batch_03_complete.csv\n",
      "Discarding \"The convicted Hynix managers/directors\"\n",
      "Discarding \"The areas that include or are included by Eurasia\"\n",
      "Discarding \"Evo Morales and Hugo Salvatierra\"\n",
      "Discarding \"The politician and the organ builder\"\n",
      "batch_04 loaded from annotations/v2_2/results/batch_04_complete.csv\n",
      "Discarding \"The country and its capital city\"\n",
      "Discarding \"The major united states city and the state nearby\"\n",
      "Discarding \"The judge and the woman he sentenced to jail\"\n",
      "Discarding \"Are in European territory\"\n",
      "Discarding \"The states that have seen declining enrollment in Medicaid\"\n",
      "batch_05 loaded from annotations/v2_2/results/batch_05_complete.csv\n",
      "Discarding \"Former attorneys and politicians\"\n",
      "Discarding \"The director/choreographers\"\n",
      "Discarding \"The writer/directors\"\n",
      "Final length of annotations: 2132.\n",
      "Done. Elapsed time: 1s.\n",
      "\n",
      "Done. Elapsed time: 3s.\n",
      "\n",
      "Filtering the annotations (initial number of annotations: 6397)...\n",
      "First filter done (number of assignments): 6360 remaining...\n",
      "Second filter done (number of answers): 5202 remaining.\n",
      "\n",
      "Unprocessed data imported (1340 ranking task).\n",
      "\n",
      "Data loaders computed:\n",
      "   train: 0 ranking tasks (0%), 0 batches,\n",
      "   valid: 670 ranking tasks (50%), 18090 batches,\n",
      "   test: 670 ranking tasks (50%), 18090 batches.\n",
      "\n",
      "Not saving ../results/modeling_task/baselines_split/contextfree_bs64.pkl (not in save mode).\n",
      "\n",
      "Data_loaders shorten to keep only the first 1 batch(es) of the first ranking task.\n",
      "\n",
      "Not saving ../results/modeling_task/baselines_split/contextfree_bs64_short.pkl (not in save mode).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "task.process_data_loaders()\n",
    "\n",
    "if short:\n",
    "    task.process_short_task(size=MODELING_TASK_SHORT_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = getattr(modeling_task, task_name)(min_assignments=MIN_ASSIGNMENTS,\n",
    "                                             min_answers=MIN_ANSWERS,\n",
    "                                             exclude_pilot=EXCLUDE_PILOT,\n",
    "                                             annotation_results_path=root + ANNOTATION_TASK_RESULTS_PATH,\n",
    "                                             batch_size=batch_size,\n",
    "                                             drop_last=DROP_LAST,\n",
    "                                             k_cross_validation=k_cross_validation,\n",
    "                                             valid_proportion=MODELS_SPLIT_VALID_PROPORTION,\n",
    "                                             test_proportion=MODELS_SPLIT_TEST_PROPORTION,\n",
    "                                             random_seed=MODELING_TASK_SEED,\n",
    "                                             save=save,\n",
    "                                             silent=silent,\n",
    "                                             results_path=root + MODELING_TASK_FOR_MODELS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the modeling task...\n",
      "Computing the annotated queries...\n",
      "Initial length of queries: 0.\n",
      "Object loaded from ../results/annotation_task/annotations/v1_0_pilot/task/queries_short.pkl.\n",
      "Object loaded from ../results/annotation_task/annotations/v1_1_pilot/task/queries_short.pkl.\n",
      "Object loaded from ../results/annotation_task/annotations/v2_0/task/queries_short.pkl.\n",
      "Object loaded from ../results/annotation_task/annotations/v2_1/task/queries.pkl.\n",
      "Object loaded from ../results/annotation_task/annotations/v2_2/task/queries.pkl.\n",
      "Final length of queries: 63141.\n",
      "Done. Elapsed time: 1s.\n",
      "\n",
      "Computing the annotations...\n",
      "Initial length of annotations: 0.\n",
      "pilot_00a.csv loaded from annotations/v1_0_pilot/results/pilot_00a.csv\n",
      "Discarding \"The priest and the student\"\n",
      "pilot_00b.csv loaded from annotations/v1_0_pilot/results/pilot_00b.csv\n",
      "pilot_01a.csv loaded from annotations/v1_1_pilot/results/pilot_01a.csv\n",
      "pilot_01b.csv loaded from annotations/v1_1_pilot/results/pilot_01b.csv\n",
      "Discarding \"France and its former colonies\"\n",
      "Discarding \"The country and its former colonies\"\n",
      "batch_00 loaded from annotations/v2_0/results/batch_00_complete.csv\n",
      "Correcting \"n this article, Nevada and Ohio are discussed. The two American states...\" to \" The two American states...\"\n",
      "Correcting \"In this article, California and Oregon are discussed. The two neighboring states...\" to \" The two neighboring states...\"\n",
      "Correcting \"In this article, California and Oregon are discussed. The two West Coast states...\" to \" The two West Coast states...\"\n",
      "batch_01 loaded from annotations/v2_0/results/batch_01_complete.csv\n",
      "Discarding \"The\"\n",
      "Discarding \"The four people involved in the Rafferty and Parker murder case\"\n",
      "Discarding \"The two people involved in the accusations against Mr. Brookins and Mr. Hernandez\"\n",
      "Discarding \"The Canadian and American politicians\"\n",
      "Correcting \"THE CHESS CHAMPIONS\" to \"The chess champions\"\n",
      "Correcting \"THE WHITE AND BLACK\" to \"The white and black\"\n",
      "Discarding \"The white and black\"\n",
      "Discarding \"The North and South America countries\"\n",
      "Discarding \"Both are politlca entities\"\n",
      "batch_02 loaded from annotations/v2_1/results/batch_02_complete.csv\n",
      "Discarding \"Both groups have a military wing\"\n",
      "Discarding \"The financial/media concern\"\n",
      "Discarding \"Both countries are in Western Asia\"\n",
      "Correcting \"FOOTBALL TEAM\" to \"Football team\"\n",
      "batch_03 loaded from annotations/v2_1/results/batch_03_complete.csv\n",
      "Discarding \"The convicted Hynix managers/directors\"\n",
      "Discarding \"The areas that include or are included by Eurasia\"\n",
      "Discarding \"Evo Morales and Hugo Salvatierra\"\n",
      "Discarding \"The politician and the organ builder\"\n",
      "batch_04 loaded from annotations/v2_2/results/batch_04_complete.csv\n",
      "Discarding \"The country and its capital city\"\n",
      "Discarding \"The major united states city and the state nearby\"\n",
      "Discarding \"The judge and the woman he sentenced to jail\"\n",
      "Discarding \"Are in European territory\"\n",
      "Discarding \"The states that have seen declining enrollment in Medicaid\"\n",
      "batch_05 loaded from annotations/v2_2/results/batch_05_complete.csv\n",
      "Discarding \"Former attorneys and politicians\"\n",
      "Discarding \"The director/choreographers\"\n",
      "Discarding \"The writer/directors\"\n",
      "Final length of annotations: 2132.\n",
      "Done. Elapsed time: 1s.\n",
      "\n",
      "Done. Elapsed time: 2s.\n",
      "\n",
      "Filtering the annotations (initial number of annotations: 6397)...\n",
      "First filter done (number of assignments): 6360 remaining...\n",
      "Second filter done (number of answers): 5202 remaining.\n",
      "\n",
      "Unprocessed data imported (1340 ranking task).\n",
      "\n",
      "Data loaders computed:\n",
      "   train: 670 ranking tasks (50%), 18090 batches,\n",
      "   valid: 335 ranking tasks (25%), 9045 batches,\n",
      "   test: 335 ranking tasks (25%), 9045 batches.\n",
      "\n",
      "Not saving ../results/modeling_task/models_split/contextfree_bs64.pkl (not in save mode).\n",
      "\n",
      "Data_loaders shorten to keep only the first 1 batch(es) of the first ranking task.\n",
      "\n",
      "Not saving ../results/modeling_task/models_split/contextfree_bs64_short.pkl (not in save mode).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "task.process_data_loaders()\n",
    "\n",
    "if short:\n",
    "    task.process_short_task(size=MODELING_TASK_SHORT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
